{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.009906,
     "end_time": "2020-08-11T04:00:16.256290",
     "exception": false,
     "start_time": "2020-08-11T04:00:16.246384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# YOLOv5 Pseudo Labeling\n",
    "\n",
    "According to the results of [this notebook](https://www.kaggle.com/nvnnghia/fasterrcnn-pseudo-labeling) FaterRCNN seems to work well with Pseudo Labeling.\n",
    "In this notebook I am going to test Pseudo labeling technique on Yolov5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-08-11T04:00:16.280134Z",
     "iopub.status.busy": "2020-08-11T04:00:16.279502Z",
     "iopub.status.idle": "2020-08-11T04:00:16.288980Z",
     "shell.execute_reply": "2020-08-11T04:00:16.288437Z"
    },
    "papermill": {
     "duration": 0.0243,
     "end_time": "2020-08-11T04:00:16.289100",
     "exception": false,
     "start_time": "2020-08-11T04:00:16.264800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import shutil as sh"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.008026,
     "end_time": "2020-08-11T04:00:16.305633",
     "exception": false,
     "start_time": "2020-08-11T04:00:16.297607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Getting yolov5 repo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-08-11T04:00:16.327381Z",
     "iopub.status.busy": "2020-08-11T04:00:16.326592Z",
     "iopub.status.idle": "2020-08-11T04:00:17.154577Z",
     "shell.execute_reply": "2020-08-11T04:00:17.152944Z"
    },
    "papermill": {
     "duration": 0.840844,
     "end_time": "2020-08-11T04:00:17.154710",
     "exception": false,
     "start_time": "2020-08-11T04:00:16.313866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/ultralytics/yolov5\n",
    "#!mv yolov5/* ./\n",
    "\n",
    "!cp -r ../input/yolov5-pseudo-labeling/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:00:17.182025Z",
     "iopub.status.busy": "2020-08-11T04:00:17.181138Z",
     "iopub.status.idle": "2020-08-11T04:00:42.284775Z",
     "shell.execute_reply": "2020-08-11T04:00:42.284077Z"
    },
    "papermill": {
     "duration": 25.120091,
     "end_time": "2020-08-11T04:00:42.284938",
     "exception": false,
     "start_time": "2020-08-11T04:00:17.164847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --no-deps '../input/weightedboxesfusion/' > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.012633,
     "end_time": "2020-08-11T04:00:42.312703",
     "exception": false,
     "start_time": "2020-08-11T04:00:42.300070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Convert train data to yolov5 format\n",
    "Based on [this notebook](https://www.kaggle.com/orkatz2/yolov5-train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:00:42.350713Z",
     "iopub.status.busy": "2020-08-11T04:00:42.349933Z",
     "iopub.status.idle": "2020-08-11T04:00:42.368610Z",
     "shell.execute_reply": "2020-08-11T04:00:42.369659Z"
    },
    "papermill": {
     "duration": 0.044164,
     "end_time": "2020-08-11T04:00:42.369817",
     "exception": false,
     "start_time": "2020-08-11T04:00:42.325653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "R_fold = 1\n",
    "def convertTrainLabel():\n",
    "    df = pd.read_csv('../input/global-wheat-detection/train.csv')\n",
    "    bboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\n",
    "    for i, column in enumerate(['x', 'y', 'w', 'h']):\n",
    "        df[column] = bboxs[:,i]\n",
    "    df.drop(columns=['bbox'], inplace=True)\n",
    "    df['x_center'] = df['x'] + df['w']/2\n",
    "    df['y_center'] = df['y'] + df['h']/2\n",
    "    df['classes'] = 0\n",
    "    from tqdm.auto import tqdm\n",
    "    import shutil as sh\n",
    "    df = df[['image_id','x', 'y', 'w', 'h','x_center','y_center','classes']]\n",
    "    \n",
    "    index = list(set(df.image_id))\n",
    "    \n",
    "    source = 'train'\n",
    "    if True:\n",
    "        for fold in [0]:\n",
    "            val_index = index[len(index)*R_fold//5:len(index)*(R_fold+1)//5]\n",
    "            for name,mini in tqdm(df.groupby('image_id')):\n",
    "                if name in val_index:\n",
    "                    path2save = 'val2017/'\n",
    "                else:\n",
    "                    path2save = 'train2017/'\n",
    "                if not os.path.exists('convertor/fold{}/labels/'.format(fold)+path2save):\n",
    "                    os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save)\n",
    "                with open('convertor/fold{}/labels/'.format(fold)+path2save+name+\".txt\", 'w+') as f:\n",
    "                    row = mini[['classes','x_center','y_center','w','h']].astype(float).values\n",
    "                    row = row/1024\n",
    "                    row = row.astype(str)\n",
    "                    for j in range(len(row)):\n",
    "                        text = ' '.join(row[j])\n",
    "                        f.write(text)\n",
    "                        f.write(\"\\n\")\n",
    "                if not os.path.exists('convertor/fold{}/images/{}'.format(fold,path2save)):\n",
    "                    os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save))\n",
    "                sh.copy(\"../input/global-wheat-detection/{}/{}.jpg\".format(source,name),'convertor/fold{}/images/{}/{}.jpg'.format(fold,path2save,name))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.010668,
     "end_time": "2020-08-11T04:00:42.392277",
     "exception": false,
     "start_time": "2020-08-11T04:00:42.381609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Some useful functions\n",
    "TTA, WBF, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:00:42.423878Z",
     "iopub.status.busy": "2020-08-11T04:00:42.423119Z",
     "iopub.status.idle": "2020-08-11T04:00:42.461191Z",
     "shell.execute_reply": "2020-08-11T04:00:42.462398Z"
    },
    "papermill": {
     "duration": 0.059311,
     "end_time": "2020-08-11T04:00:42.462581",
     "exception": false,
     "start_time": "2020-08-11T04:00:42.403270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ensemble_boxes import *\n",
    "def run_wbf(boxes, scores, image_size=1023, iou_thr=0.5, skip_box_thr=0.7, weights=None):\n",
    "    #boxes = [prediction[image_index]['boxes'].data.cpu().numpy()/(image_size-1) for prediction in predictions]\n",
    "    #scores = [prediction[image_index]['scores'].data.cpu().numpy() for prediction in predictions]\n",
    "    labels = [np.zeros(score.shape[0]) for score in scores]\n",
    "    boxes = [box/(image_size) for box in boxes]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    #boxes, scores, labels = nms(boxes, scores, labels, weights=[1,1,1,1,1], iou_thr=0.5)\n",
    "    boxes = boxes*(image_size)\n",
    "    return boxes, scores, labels\n",
    "\n",
    "def TTAImage(image, index):\n",
    "    image1 = image.copy()\n",
    "    if index==0: \n",
    "        rotated_image = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n",
    "        return rotated_image\n",
    "    elif index==1:\n",
    "        rotated_image2 = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n",
    "        rotated_image2 = cv2.rotate(rotated_image2, cv2.ROTATE_90_CLOCKWISE)\n",
    "        return rotated_image2\n",
    "    elif index==2:\n",
    "        rotated_image3 = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n",
    "        rotated_image3 = cv2.rotate(rotated_image3, cv2.ROTATE_90_CLOCKWISE)\n",
    "        rotated_image3 = cv2.rotate(rotated_image3, cv2.ROTATE_90_CLOCKWISE)\n",
    "        return rotated_image3\n",
    "    elif index == 3:\n",
    "        return image1\n",
    "    \n",
    "def rotBoxes90(boxes, im_w, im_h):\n",
    "    ret_boxes =[]\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        x1, y1, x2, y2 = x1-im_w//2, im_h//2 - y1, x2-im_w//2, im_h//2 - y2\n",
    "        x1, y1, x2, y2 = y1, -x1, y2, -x2\n",
    "        x1, y1, x2, y2 = int(x1+im_w//2), int(im_h//2 - y1), int(x2+im_w//2), int(im_h//2 - y2)\n",
    "        x1a, y1a, x2a, y2a = min(x1, x2), min(y1, y2), max(x1, x2), max(y1, y2)\n",
    "        ret_boxes.append([x1a, y1a, x2a, y2a])\n",
    "    return np.array(ret_boxes)\n",
    "\n",
    "def detect1Image(im0, imgsz, model, device, conf_thres, iou_thres):\n",
    "    img = letterbox(im0, new_shape=imgsz)[0]\n",
    "    # Convert\n",
    "    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "    img = np.ascontiguousarray(img)\n",
    "\n",
    "\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img =  img.float()  # uint8 to fp16/32\n",
    "    img /= 255.0   \n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    # Inference\n",
    "    pred = model(img, augment=False)[0]\n",
    "\n",
    "    # Apply NMS\n",
    "    pred = non_max_suppression(pred, conf_thres, iou_thres)\n",
    "\n",
    "    boxes = []\n",
    "    scores = []\n",
    "    for i, det in enumerate(pred):  # detections per image\n",
    "        # save_path = 'draw/' + image_id + '.jpg'\n",
    "        if det is not None and len(det):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "            # Write results\n",
    "            for *xyxy, conf, cls in det:\n",
    "                boxes.append([int(xyxy[0]), int(xyxy[1]), int(xyxy[2]), int(xyxy[3])])\n",
    "                scores.append(conf)\n",
    "\n",
    "    return np.array(boxes), np.array(scores) "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.010485,
     "end_time": "2020-08-11T04:00:42.484680",
     "exception": false,
     "start_time": "2020-08-11T04:00:42.474195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make pseudo labels for Yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:00:42.524773Z",
     "iopub.status.busy": "2020-08-11T04:00:42.523862Z",
     "iopub.status.idle": "2020-08-11T04:00:45.644976Z",
     "shell.execute_reply": "2020-08-11T04:00:45.644204Z"
    },
    "papermill": {
     "duration": 3.144906,
     "end_time": "2020-08-11T04:00:45.645099",
     "exception": false,
     "start_time": "2020-08-11T04:00:42.500193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.datasets import *\n",
    "from utils.utils import *\n",
    "\n",
    "def makePseudolabel(weights = '../input/yolov5pth/weightsbest_yolov5x_fold3.pt'):\n",
    "    source = '../input/global-wheat-detection/test/'\n",
    "#     weights = '../input/yolov5pth/weightsbest_yolov5x_fold3.pt'\n",
    "    imgsz = 1024\n",
    "    conf_thres = 0.5\n",
    "    iou_thres = 0.6\n",
    "    is_TTA = True\n",
    "    \n",
    "    imagenames =  os.listdir(source)\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # Load model\n",
    "    model = torch.load(weights, map_location=device)['model'].float()  # load to FP32\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    dataset = LoadImages(source, img_size=imgsz)\n",
    "\n",
    "    path2save = 'train2017/'\n",
    "    if not os.path.exists('convertor/fold0/labels/'+path2save):\n",
    "        os.makedirs('convertor/fold0/labels/'+path2save)\n",
    "    if not os.path.exists('convertor/fold0/images/{}'.format(path2save)):\n",
    "        os.makedirs('convertor/fold0/images/{}'.format(path2save))\n",
    "            \n",
    "    for name in tqdm(imagenames):\n",
    "        image_id = name.split('.')[0]\n",
    "        im01 = cv2.imread('%s/%s.jpg'%(source,image_id))  # BGR\n",
    "#         im01 = cv2.resize(im01,(1024,1024))\n",
    "        if im01.shape[0]!=1024 or im01.shape[1]!=1024:\n",
    "            continue\n",
    "        assert im01 is not None, 'Image Not Found '\n",
    "        # Padded resize\n",
    "        im_w, im_h = im01.shape[:2]\n",
    "        if is_TTA:\n",
    "            enboxes = []\n",
    "            enscores = []\n",
    "            for i in range(4):\n",
    "                im0 = TTAImage(im01, i)\n",
    "                boxes, scores = detect1Image(im0, imgsz, model, device, conf_thres, iou_thres)\n",
    "                for _ in range(3-i):\n",
    "                    boxes = rotBoxes90(boxes, im_w, im_h)\n",
    "                    \n",
    "                enboxes.append(boxes)\n",
    "                enscores.append(scores) \n",
    "\n",
    "            boxes, scores, labels = run_wbf(enboxes, enscores, image_size = im_w, iou_thr=0.6, skip_box_thr=0.43)\n",
    "            boxes = boxes.astype(np.int32).clip(min=0, max=im_w)\n",
    "        else:\n",
    "            boxes, scores = detect1Image(im01, imgsz, model, device, conf_thres, iou_thres)\n",
    "\n",
    "        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "        \n",
    "        boxes = boxes[scores >= 0.1].astype(np.int32)\n",
    "        scores = scores[scores >=float(0.1)]\n",
    "        \n",
    "        lineo = ''\n",
    "        for box in boxes:\n",
    "            x1, y1, w, h = box\n",
    "            xc, yc, w, h = (x1+w/2)/1024, (y1+h/2)/1024, w/1024, h/1024\n",
    "            lineo += '0 %f %f %f %f\\n'%(xc, yc, w, h)\n",
    "            \n",
    "        fileo = open('convertor/fold0/labels/'+path2save+image_id+\".txt\", 'w+')\n",
    "        fileo.write(lineo)\n",
    "        fileo.close()\n",
    "        sh.copy(\"../input/global-wheat-detection/test/{}.jpg\".format(image_id),'convertor/fold0/images/{}/{}.jpg'.format(path2save,image_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:00:45.669222Z",
     "iopub.status.busy": "2020-08-11T04:00:45.668601Z",
     "iopub.status.idle": "2020-08-11T04:01:05.243230Z",
     "shell.execute_reply": "2020-08-11T04:01:05.243809Z"
    },
    "papermill": {
     "duration": 19.589997,
     "end_time": "2020-08-11T04:01:05.243985",
     "exception": false,
     "start_time": "2020-08-11T04:00:45.653988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0cdad7dbf5430b99ecb1f4feb73149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3373.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convertTrainLabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:01:05.267069Z",
     "iopub.status.busy": "2020-08-11T04:01:05.266442Z",
     "iopub.status.idle": "2020-08-11T04:01:05.718942Z",
     "shell.execute_reply": "2020-08-11T04:01:05.719551Z"
    },
    "papermill": {
     "duration": 0.465582,
     "end_time": "2020-08-11T04:01:05.719708",
     "exception": false,
     "start_time": "2020-08-11T04:01:05.254126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/yolov5pth/weightsbest_yolov5x_fold3.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-331e48433b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmakePseudolabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-cc0e3dbf2ef3>\u001b[0m in \u001b[0;36mmakePseudolabel\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load to FP32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/yolov5pth/weightsbest_yolov5x_fold3.pt'"
     ]
    }
   ],
   "source": [
    "makePseudolabel()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.008658,
     "end_time": "2020-08-11T04:01:05.737777",
     "exception": false,
     "start_time": "2020-08-11T04:01:05.729119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Retrain yolov5 with pseudo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:01:05.765079Z",
     "iopub.status.busy": "2020-08-11T04:01:05.764324Z",
     "iopub.status.idle": "2020-08-11T04:01:06.637206Z",
     "shell.execute_reply": "2020-08-11T04:01:06.636568Z"
    },
    "papermill": {
     "duration": 0.890153,
     "end_time": "2020-08-11T04:01:06.637328",
     "exception": false,
     "start_time": "2020-08-11T04:01:05.747175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(os.listdir('../input/global-wheat-detection/test/'))<11:\n",
    "    pass\n",
    "#     !python train.py --img 1024 --batch 4 --epochs 1 --data ../input/configyolo5/wheat0.yaml --cfg ../input/newcon/yolov5x3.yaml --weights ../input/yolov5pth/weightsbest_yolov5x_fold3.pt  \n",
    "else:\n",
    "    !python train.py --img 1024 --batch 4 --epochs 10 --data ../input/configyolo5/wheat0.yaml --cfg ../input/newcon/yolov5x3.yaml --weights ../input/yolov5pth/weightsbest_yolov5x_fold3.pt    \n",
    "!rm -rf convertor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:01:06.660692Z",
     "iopub.status.busy": "2020-08-11T04:01:06.660083Z",
     "iopub.status.idle": "2020-08-11T04:01:06.664371Z",
     "shell.execute_reply": "2020-08-11T04:01:06.663835Z"
    },
    "papermill": {
     "duration": 0.017476,
     "end_time": "2020-08-11T04:01:06.664468",
     "exception": false,
     "start_time": "2020-08-11T04:01:06.646992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if not os.path.exists('weights/best.pt'):\n",
    "#     weights = '../input/yolov5pth/best_yolov5x_fold3.pt'\n",
    "# else:\n",
    "#     convertTrainLabel()\n",
    "#     makePseudolabel(weights = 'weights/best.pt')\n",
    "#     if len(os.listdir('../input/global-wheat-detection/test/'))<11:\n",
    "#         !python train.py --img 1024 --batch 4 --epochs 1 --data ../input/configyolo5/wheat0.yaml --cfg ../input/newcon/yolov5x3.yaml --weights weights/best.pt \n",
    "#     else:\n",
    "#         !python train.py --img 1024 --batch 4 --epochs 4 --data ../input/configyolo5/wheat0.yaml --cfg ../input/newcon/yolov5x3.yaml --weights weights/best.pt  \n",
    "#     !rm -rf convertor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:01:06.690997Z",
     "iopub.status.busy": "2020-08-11T04:01:06.689153Z",
     "iopub.status.idle": "2020-08-11T04:01:06.691681Z",
     "shell.execute_reply": "2020-08-11T04:01:06.692172Z"
    },
    "papermill": {
     "duration": 0.018726,
     "end_time": "2020-08-11T04:01:06.692289",
     "exception": false,
     "start_time": "2020-08-11T04:01:06.673563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_prediction_string(boxes, scores):\n",
    "    pred_strings = []\n",
    "    for j in zip(scores, boxes):\n",
    "        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n",
    "\n",
    "    return \" \".join(pred_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.008847,
     "end_time": "2020-08-11T04:01:06.710144",
     "exception": false,
     "start_time": "2020-08-11T04:01:06.701297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:01:06.732207Z",
     "iopub.status.busy": "2020-08-11T04:01:06.731566Z",
     "iopub.status.idle": "2020-08-11T04:01:06.735786Z",
     "shell.execute_reply": "2020-08-11T04:01:06.735277Z"
    },
    "papermill": {
     "duration": 0.016544,
     "end_time": "2020-08-11T04:01:06.735879",
     "exception": false,
     "start_time": "2020-08-11T04:01:06.719335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cp ../input/yolo5tta4/yolo.py ./models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:01:06.761157Z",
     "iopub.status.busy": "2020-08-11T04:01:06.759198Z",
     "iopub.status.idle": "2020-08-11T04:01:06.761811Z",
     "shell.execute_reply": "2020-08-11T04:01:06.762282Z"
    },
    "papermill": {
     "duration": 0.016962,
     "end_time": "2020-08-11T04:01:06.762394",
     "exception": false,
     "start_time": "2020-08-11T04:01:06.745432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.datasets import *\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:01:06.794628Z",
     "iopub.status.busy": "2020-08-11T04:01:06.793893Z",
     "iopub.status.idle": "2020-08-11T04:01:06.797069Z",
     "shell.execute_reply": "2020-08-11T04:01:06.797544Z"
    },
    "papermill": {
     "duration": 0.025904,
     "end_time": "2020-08-11T04:01:06.797653",
     "exception": false,
     "start_time": "2020-08-11T04:01:06.771749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect1Image_aug(im0, imgsz, model, device, conf_thres, iou_thres):\n",
    "    img = letterbox(im0, new_shape=imgsz)[0]\n",
    "    # Convert\n",
    "    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "    img = np.ascontiguousarray(img)\n",
    "\n",
    "\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img =  img.float()  # uint8 to fp16/32\n",
    "    img /= 255.0   \n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    # Inference\n",
    "    pred = model(img, augment=True)[0]\n",
    "\n",
    "    # Apply NMS\n",
    "    pred = non_max_suppression(pred, conf_thres, iou_thres)\n",
    "\n",
    "    boxes = []\n",
    "    scores = []\n",
    "    for i, det in enumerate(pred):  # detections per image\n",
    "        # save_path = 'draw/' + image_id + '.jpg'\n",
    "        if det is not None and len(det):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "            # Write results\n",
    "            for *xyxy, conf, cls in det:\n",
    "                boxes.append([int(xyxy[0]), int(xyxy[1]), int(xyxy[2]), int(xyxy[3])])\n",
    "                scores.append(conf)\n",
    "\n",
    "    return np.array(boxes), np.array(scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:01:06.824640Z",
     "iopub.status.busy": "2020-08-11T04:01:06.823823Z",
     "iopub.status.idle": "2020-08-11T04:01:06.826966Z",
     "shell.execute_reply": "2020-08-11T04:01:06.826447Z"
    },
    "papermill": {
     "duration": 0.020275,
     "end_time": "2020-08-11T04:01:06.827058",
     "exception": false,
     "start_time": "2020-08-11T04:01:06.806783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clip_coords2(boxes, img_shape):\n",
    "    # Clip bounding xyxy bounding boxes to image shape (height, width)\n",
    "    boxes[:, 0].clamp_(0, img_shape[1])  # x1\n",
    "    boxes[:, 1].clamp_(0, img_shape[0])  # y1\n",
    "    boxes[:, 2].clamp_(0, img_shape[1])  # x2\n",
    "    boxes[:, 3].clamp_(0, img_shape[0])  # y2\n",
    "    \n",
    "def scale_coords2(coords,factorx,factory, img0_shape):\n",
    "    coords[:, 0::2] *= factorx  # x padding\n",
    "    coords[:, 1::2] *= factory  # y padding\n",
    "    clip_coords2(coords, img0_shape)\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:01:06.858945Z",
     "iopub.status.busy": "2020-08-11T04:01:06.851355Z",
     "iopub.status.idle": "2020-08-11T04:01:52.657322Z",
     "shell.execute_reply": "2020-08-11T04:01:52.658147Z"
    },
    "papermill": {
     "duration": 45.821983,
     "end_time": "2020-08-11T04:01:52.658325",
     "exception": false,
     "start_time": "2020-08-11T04:01:06.836342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null\n",
    "!pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:01:52.700265Z",
     "iopub.status.busy": "2020-08-11T04:01:52.696824Z",
     "iopub.status.idle": "2020-08-11T04:06:18.340361Z",
     "shell.execute_reply": "2020-08-11T04:06:18.339596Z"
    },
    "papermill": {
     "duration": 265.671856,
     "end_time": "2020-08-11T04:06:18.340499",
     "exception": false,
     "start_time": "2020-08-11T04:01:52.668643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/orkatzfdata/yacs-0.1.7-py3-none-any.whl\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from yacs==0.1.7) (5.3.1)\r\n",
      "Installing collected packages: yacs\r\n",
      "Successfully installed yacs-0.1.7\r\n",
      "Processing ./fvcore/fvcore-0.1.dev200407\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore==0.1.dev200407) (1.18.1)\r\n",
      "Requirement already satisfied: yacs>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from fvcore==0.1.dev200407) (0.1.7)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from fvcore==0.1.dev200407) (5.3.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from fvcore==0.1.dev200407) (4.45.0)\r\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from fvcore==0.1.dev200407) (1.7.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (from fvcore==0.1.dev200407) (1.1.0)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from fvcore==0.1.dev200407) (5.4.1)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from fvcore==0.1.dev200407) (0.8.7)\r\n",
      "Building wheels for collected packages: fvcore\r\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.dev200407-py3-none-any.whl size=38762 sha256=f88ee7553248fc7929ebdc9ba6abc698d826db01f0d1ba8ad95f50e18d75020d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/e5/f3/be414e6471636ec89b15d85636ec76836ce2fbacb74d98c7e3\r\n",
      "Successfully built fvcore\r\n",
      "Installing collected packages: fvcore\r\n",
      "Successfully installed fvcore-0.1.dev200407\r\n",
      "Processing ./detectron2-ResNeSt\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.1.1) (1.1.0)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from detectron2==0.1.1) (5.4.1)\r\n",
      "Requirement already satisfied: yacs>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.1.1) (0.1.7)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from detectron2==0.1.1) (0.8.7)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from detectron2==0.1.1) (1.3.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from detectron2==0.1.1) (3.2.1)\r\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.1.1) (4.45.0)\r\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from detectron2==0.1.1) (2.2.2)\r\n",
      "Requirement already satisfied: fvcore==0.1.dev200407 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.1.1) (0.1.dev200407)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from detectron2==0.1.1) (0.18.2)\r\n",
      "Requirement already satisfied: pydot in /opt/conda/lib/python3.7/site-packages (from detectron2==0.1.1) (1.4.1)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from yacs>=0.1.6->detectron2==0.1.1) (5.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.1.1) (0.10.0)\r\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.1.1) (1.18.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.1.1) (1.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.1.1) (2.8.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.1.1) (2.4.7)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (0.4.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (3.2.1)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (0.9.0)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (1.14.0)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (1.29.0)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (1.6.0.post3)\r\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (0.34.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (2.23.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (1.0.1)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (1.14.0)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.1.1) (3.11.4)\r\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from fvcore==0.1.dev200407->detectron2==0.1.1) (1.7.0)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.1) (1.2.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.1) (0.2.7)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.1) (3.1.1)\r\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.1) (4.0)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.1) (1.24.3)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.1) (3.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.1) (2020.4.5.1)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.1.1) (2.9)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.1.1) (3.0.1)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2==0.1.1) (0.4.8)\r\n",
      "Building wheels for collected packages: detectron2\r\n",
      "  Building wheel for detectron2 (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for detectron2: filename=detectron2-0.1.1-cp37-cp37m-linux_x86_64.whl size=4872812 sha256=f8f767245bf83781bc9c922fa7508c9b69e8b63b09037ffecb320256a5fa4461\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0f/f3/e1/8a8e7f0a7e7fcc4215726cbd3a05188930dbe6fe04dc585379\r\n",
      "Successfully built detectron2\r\n",
      "Installing collected packages: detectron2\r\n",
      "Successfully installed detectron2-0.1.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/orkatzfdata/yacs-0.1.7-py3-none-any.whl\n",
    "!mkdir fvcore\n",
    "!cp -R '/kaggle/input/orkatzfdata/fvcore-0.1.dev200407/fvcore-0.1.dev200407/' ./fvcore\n",
    "!pip install fvcore/fvcore-0.1.dev200407/.\n",
    "!mkdir detectron2-ResNeSt\n",
    "!cp -R /kaggle/input/orkatzfdata/detectron2-ResNeSt/* ./detectron2-ResNeSt/\n",
    "!pip install detectron2-ResNeSt/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:06:18.376938Z",
     "iopub.status.busy": "2020-08-11T04:06:18.376128Z",
     "iopub.status.idle": "2020-08-11T04:06:19.676400Z",
     "shell.execute_reply": "2020-08-11T04:06:19.675721Z"
    },
    "papermill": {
     "duration": 1.32367,
     "end_time": "2020-08-11T04:06:19.676532",
     "exception": false,
     "start_time": "2020-08-11T04:06:18.352862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../input/timm-efficientdet-pytorch\")\n",
    "sys.path.insert(0, \"../input/omegaconf\")\n",
    "import os\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "from ensemble_boxes import *\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchEval\n",
    "from effdet.efficientdet import HeadNet\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from skopt import gp_minimize, forest_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.plots import plot_objective, plot_evaluations, plot_convergence, plot_regret\n",
    "from skopt.space import Categorical, Integer, Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:06:19.715703Z",
     "iopub.status.busy": "2020-08-11T04:06:19.714170Z",
     "iopub.status.idle": "2020-08-11T04:06:19.716838Z",
     "shell.execute_reply": "2020-08-11T04:06:19.717376Z"
    },
    "papermill": {
     "duration": 0.028353,
     "end_time": "2020-08-11T04:06:19.717495",
     "exception": false,
     "start_time": "2020-08-11T04:06:19.689142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_net(checkpoint_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d5')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "\n",
    "    config.num_classes = 1\n",
    "    config.image_size = 512\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    net.load_state_dict(checkpoint)\n",
    "\n",
    "    del checkpoint\n",
    "    gc.collect()\n",
    "\n",
    "    net = DetBenchEval(net, config)\n",
    "    net.eval();\n",
    "    return net.cuda()\n",
    "\n",
    "def load_net7(checkpoint_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d7')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "\n",
    "    config.num_classes = 1\n",
    "    config.image_size = 1024\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    del checkpoint\n",
    "    gc.collect()\n",
    "\n",
    "    net = DetBenchEval(net, config)\n",
    "    net.eval();\n",
    "    return net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:06:19.753690Z",
     "iopub.status.busy": "2020-08-11T04:06:19.752839Z",
     "iopub.status.idle": "2020-08-11T04:06:26.678827Z",
     "shell.execute_reply": "2020-08-11T04:06:26.678128Z"
    },
    "papermill": {
     "duration": 6.950247,
     "end_time": "2020-08-11T04:06:26.679005",
     "exception": false,
     "start_time": "2020-08-11T04:06:19.728758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/tempb7/best-checkpoint-015epoch.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-74f62fbda666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m models2 = [load_net7('../input/tempb7/best-checkpoint-015epoch.bin'),\n\u001b[0m\u001b[1;32m      2\u001b[0m            \u001b[0mload_net7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/tempb7/best-checkpoint-020epoch.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m            load_net7('../input/tempb7/best-checkpoint-022epoch.bin'),]\n\u001b[1;32m      4\u001b[0m models = [\n\u001b[1;32m      5\u001b[0m         \u001b[0mload_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/effdetbestpth/best-fold0-augmix.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-da0be75c15ce>\u001b[0m in \u001b[0;36mload_net7\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHeadNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/tempb7/best-checkpoint-015epoch.bin'"
     ]
    }
   ],
   "source": [
    "models2 = [load_net7('../input/tempb7/best-checkpoint-015epoch.bin'),\n",
    "           load_net7('../input/tempb7/best-checkpoint-020epoch.bin'),\n",
    "           load_net7('../input/tempb7/best-checkpoint-022epoch.bin'),]\n",
    "models = [\n",
    "        load_net('../input/effdetbestpth/best-fold0-augmix.pth'),\n",
    "        load_net('../input/effdetbestpth/best-fold3.pth'),\n",
    "        load_net('../input/effdetbestpth/best-fold4.pth'),\n",
    "        load_net('../input/effdetbestpth/best-fold1-augmix.pth'),\n",
    "        load_net('../input/effdetbestpth/best-fold2-augmix.pth'),\n",
    "        load_net('../input/effdetbestpth/fold0-best.bin')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:06:26.714144Z",
     "iopub.status.busy": "2020-08-11T04:06:26.713370Z",
     "iopub.status.idle": "2020-08-11T04:06:29.655490Z",
     "shell.execute_reply": "2020-08-11T04:06:29.654716Z"
    },
    "papermill": {
     "duration": 2.963082,
     "end_time": "2020-08-11T04:06:29.655632",
     "exception": false,
     "start_time": "2020-08-11T04:06:26.692550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "cfg = get_cfg()\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_cascade_rcnn_ResNeSt_101_FPN_syncbn_range-scale_1x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # \n",
    "\n",
    "\n",
    "cfg.MODEL.WEIGHTS = os.path.join('/kaggle/input/best-inrae-1/', \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.47  # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"m5_val\", )\n",
    "predictor1 = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:06:29.684699Z",
     "iopub.status.busy": "2020-08-11T04:06:29.684110Z",
     "iopub.status.idle": "2020-08-11T04:06:29.688576Z",
     "shell.execute_reply": "2020-08-11T04:06:29.688003Z"
    },
    "papermill": {
     "duration": 0.020224,
     "end_time": "2020-08-11T04:06:29.688684",
     "exception": false,
     "start_time": "2020-08-11T04:06:29.668460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models3 =[predictor1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:06:29.730498Z",
     "iopub.status.busy": "2020-08-11T04:06:29.729156Z",
     "iopub.status.idle": "2020-08-11T04:06:29.733410Z",
     "shell.execute_reply": "2020-08-11T04:06:29.732876Z"
    },
    "papermill": {
     "duration": 0.033081,
     "end_time": "2020-08-11T04:06:29.733511",
     "exception": false,
     "start_time": "2020-08-11T04:06:29.700430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_ROOT_PATH = '../input/global-wheat-detection/test'\n",
    "\n",
    "class TestDatasetRetriever(Dataset):\n",
    "\n",
    "    def __init__(self, image_ids, transforms=None,transforms2=None):\n",
    "        super().__init__()\n",
    "        self.image_ids = image_ids\n",
    "        self.transforms = transforms\n",
    "        self.transforms2 = transforms2\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.image_ids[index]\n",
    "        image = cv2.imread(f'{DATA_ROOT_PATH}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        if self.transforms:\n",
    "            sample = {'image': image}\n",
    "            sample = self.transforms(**sample)\n",
    "            image0 = sample['image']\n",
    "        if self.transforms2:\n",
    "            sample = {'image': image}\n",
    "            sample = self.transforms2(**sample)\n",
    "            image1 = sample['image']\n",
    "        return image0,image1, image_id\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(height=512, width=512, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], \n",
    "        p=1.0, \n",
    "    )\n",
    "\n",
    "def get_valid_transforms2():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(height=1024, width=1024, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], \n",
    "        p=1.0, \n",
    "    )\n",
    "\n",
    "dataset = TestDatasetRetriever(\n",
    "    image_ids=np.array([path.split('/')[-1][:-4] for path in glob(f'{DATA_ROOT_PATH}/*.jpg')]),\n",
    "    transforms=get_valid_transforms(),transforms2=get_valid_transforms2()\n",
    ")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:06:29.784099Z",
     "iopub.status.busy": "2020-08-11T04:06:29.779708Z",
     "iopub.status.idle": "2020-08-11T04:06:29.786820Z",
     "shell.execute_reply": "2020-08-11T04:06:29.786349Z"
    },
    "papermill": {
     "duration": 0.041873,
     "end_time": "2020-08-11T04:06:29.786934",
     "exception": false,
     "start_time": "2020-08-11T04:06:29.745061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_predictions(\n",
    "    images, images1,image_ids,\n",
    "    score_threshold=0.25,\n",
    "):\n",
    "    images = images.cuda().float()\n",
    "    images1 = images1.cuda().float()\n",
    "    image_id = image_ids\n",
    "    rh,rw,_ = cv2.imread(f'{DATA_ROOT_PATH}/{image_id}.jpg').shape\n",
    "    Hscale512 = rh/512\n",
    "    Wscale512 = rw/512\n",
    "    \n",
    "    Hscale1024 = rh/1024\n",
    "    Wscale1024 = rw/1024\n",
    "    predictions = []\n",
    "    for fold_number, net in enumerate(models):\n",
    "        with torch.no_grad():\n",
    "            det = net(images, torch.tensor([1]*images.shape[0]).float().cuda())\n",
    "            result = []\n",
    "            for i in range(images.shape[0]):\n",
    "                boxes = det[i].detach().cpu().numpy()[:,:4]    \n",
    "                scores = det[i].detach().cpu().numpy()[:,4]\n",
    "                indexes = np.where(scores > score_threshold)[0]\n",
    "#                 boxes = boxes[indexes]\n",
    "                boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "                boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "                \n",
    "                boxes[:, 0::2] *= Wscale512\n",
    "                boxes[:, 1::2] *= Hscale512\n",
    "                result.append({\n",
    "                    'boxes': boxes[indexes],\n",
    "                    'scores': scores[indexes],\n",
    "                })\n",
    "            predictions.append(result)\n",
    "    \n",
    "    for fold_number, net in enumerate(models2):\n",
    "        with torch.no_grad():\n",
    "            det = net(images1, torch.tensor([1]*images1.shape[0]).float().cuda())\n",
    "            result = []\n",
    "            for i in range(images.shape[0]):\n",
    "                boxes = det[i].detach().cpu().numpy()[:,:4]    \n",
    "                scores = det[i].detach().cpu().numpy()[:,4]\n",
    "                indexes = np.where(scores > score_threshold)[0]\n",
    "#                 boxes = boxes[indexes]\n",
    "                boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "                boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "                boxes[:, 0::2] *= Wscale1024\n",
    "                boxes[:, 1::2] *= Hscale1024\n",
    "                result.append({\n",
    "                    'boxes': boxes[indexes],\n",
    "                    'scores': scores[indexes],\n",
    "                })\n",
    "            predictions.append(result)\n",
    "    for fold_number, net in enumerate(models3):\n",
    "        image_id = image_ids\n",
    "        result =[]\n",
    "        with torch.no_grad():\n",
    "            im = cv2.imread(f'{DATA_ROOT_PATH}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "            outputs = predictor1(im)\n",
    "            out = outputs[\"instances\"].to(\"cpu\")\n",
    "            scores = out.get_fields()['scores'].numpy()\n",
    "            boxes = out.get_fields()['pred_boxes'].tensor.numpy().astype(int)\n",
    "            labels= out.get_fields()['scores'].numpy()\n",
    "            result.append({\n",
    "                    'boxes': boxes,\n",
    "                    'scores': scores,\n",
    "                })\n",
    "            predictions.append(result)\n",
    "            predictions.append(result)\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:06:29.823476Z",
     "iopub.status.busy": "2020-08-11T04:06:29.821605Z",
     "iopub.status.idle": "2020-08-11T04:06:29.824152Z",
     "shell.execute_reply": "2020-08-11T04:06:29.824604Z"
    },
    "papermill": {
     "duration": 0.022895,
     "end_time": "2020-08-11T04:06:29.824714",
     "exception": false,
     "start_time": "2020-08-11T04:06:29.801819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clip_coords3(boxes, img_shape):\n",
    "    # Clip bounding xyxy bounding boxes to image shape (height, width)\n",
    "    boxes[:, 0].clamp_(0, img_shape[1])  # x1\n",
    "    boxes[:, 1].clamp_(0, img_shape[0])  # y1\n",
    "    boxes[:, 2].clamp_(0, img_shape[1])  # x2\n",
    "    boxes[:, 3].clamp_(0, img_shape[0])  # y2\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:06:29.858182Z",
     "iopub.status.busy": "2020-08-11T04:06:29.856445Z",
     "iopub.status.idle": "2020-08-11T04:06:29.858884Z",
     "shell.execute_reply": "2020-08-11T04:06:29.859387Z"
    },
    "papermill": {
     "duration": 0.023062,
     "end_time": "2020-08-11T04:06:29.859498",
     "exception": false,
     "start_time": "2020-08-11T04:06:29.836436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_wbf2(predictions, image_index, image_size=1024, iou_thr=0.34, skip_box_thr=0.33, weights=None):\n",
    "    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions]#+ [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions1]\n",
    "    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]#+[prediction[image_index]['scores'].tolist()  for prediction in predictions1]\n",
    "    labels = [np.ones(prediction[image_index]['scores'].shape[0]).tolist() for prediction in predictions]#+[np.ones(prediction[image_index]['scores'].shape[0]).tolist() for prediction in predictions1]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    boxes = boxes*(image_size-1)\n",
    "    return boxes, scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:06:29.917770Z",
     "iopub.status.busy": "2020-08-11T04:06:29.901709Z",
     "iopub.status.idle": "2020-08-11T04:06:29.920660Z",
     "shell.execute_reply": "2020-08-11T04:06:29.920158Z"
    },
    "papermill": {
     "duration": 0.049495,
     "end_time": "2020-08-11T04:06:29.920751",
     "exception": false,
     "start_time": "2020-08-11T04:06:29.871256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect():\n",
    "    transforms = get_valid_transforms()\n",
    "    transforms2 = get_valid_transforms2()\n",
    "    source = '../input/global-wheat-detection/test/'\n",
    "    weights = 'weights/best.pt'\n",
    "    weights800 = '../input/yolo800/best_yolov5x_fold0_800.pt'\n",
    "    if not os.path.exists(weights):\n",
    "        weights = '../input/yolov5pth/weightsbest_yolov5x_fold3.pt'\n",
    "    imgsz = 1024\n",
    "    conf_thres = 0.34\n",
    "    iou_thres = 0.45\n",
    "    is_TTA = True\n",
    "    \n",
    "    imagenames =  os.listdir(source)\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # Load model\n",
    "    model = torch.load(weights, map_location=device)['model'].float()  # load to FP32\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    model800 = torch.load(weights800, map_location=device)['model'].float()  # load to FP32\n",
    "    model800.to(device).eval()\n",
    "    \n",
    "    dataset = LoadImages(source, img_size=imgsz)\n",
    "\n",
    "    results = []\n",
    "    fig, ax = plt.subplots(5, 2, figsize=(30, 70))\n",
    "    count = 0\n",
    "    # img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
    "    #for path, img, im0s, _ in dataset:\n",
    "    for name in tqdm(imagenames):\n",
    "        image_id = name.split('.')[0]\n",
    "        im01 = cv2.imread('%s/%s.jpg'%(source,image_id))  # BGR\n",
    "        image = cv2.cvtColor(im01, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        sample = {'image': image}\n",
    "        sample = transforms(**sample)\n",
    "        image0 = sample['image'] #512\n",
    "\n",
    "        sample = {'image': image}\n",
    "        sample = transforms2(**sample)\n",
    "        image1 = sample['image'] #1024\n",
    "        \n",
    "        if image1.ndimension() == 3:\n",
    "            image1 = image1.unsqueeze(0)\n",
    "            image0 = image0.unsqueeze(0)\n",
    "        assert im01 is not None, 'Image Not Found '\n",
    "        # Padded resize\n",
    "        im_w, im_h = im01.shape[:2]\n",
    "        if is_TTA:\n",
    "            enboxes = []\n",
    "            enscores = []\n",
    "            for i in range(4):\n",
    "                im0 = TTAImage(im01, i)\n",
    "                boxes, scores = detect1Image(im0, imgsz, model, device, conf_thres, iou_thres)\n",
    "                for _ in range(3-i):\n",
    "                    boxes = rotBoxes90(boxes, im_w, im_h)\n",
    "                    \n",
    "                if 1: #i<3:\n",
    "                    enboxes.append(boxes)\n",
    "                    enscores.append(scores) \n",
    "                    \n",
    "            boxes, scores = detect1Image(im01, imgsz, model, device, conf_thres, iou_thres)\n",
    "            enboxes.append(boxes)\n",
    "            enscores.append(scores)\n",
    "            enboxes.append(boxes)\n",
    "            enscores.append(scores)\n",
    "            \n",
    "#             boxes, scores = detect1Image_aug(im01, 800, model800, device, 0.1, 0.94)\n",
    "#             boxes, scores, labels = run_wbf([boxes], [scores], image_size = 800, iou_thr=0.4, skip_box_thr=0.3)\n",
    "#             enboxes.append(boxes)\n",
    "#             enscores.append(scores)\n",
    "\n",
    "\n",
    "            \n",
    "            predictions = make_predictions(image0,image1,image_id)\n",
    "            boxes, scores, labels = run_wbf2(predictions, image_index=0)\n",
    "            \n",
    "            enboxes.append(boxes)\n",
    "            enscores.append(scores)\n",
    "            enboxes.append(boxes)\n",
    "            enscores.append(scores)\n",
    "            \n",
    "            \n",
    "            boxes, scores, labels = run_wbf(enboxes, enscores, image_size = im_w, iou_thr=0.48, skip_box_thr=0.575)\n",
    "            boxes = boxes.astype(np.int32).clip(min=0, max=im_w)\n",
    "        else:\n",
    "            boxes, scores = detect1Image(im01, imgsz, model, device, conf_thres, iou_thres)\n",
    "\n",
    "        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "        \n",
    "        boxes = boxes[scores >= 0.05].astype(np.int32)\n",
    "        scores = scores[scores >=float(0.05)]\n",
    "        if count<10:\n",
    "            #sample = image.permute(1,2,0).cpu().numpy()\n",
    "            for box, score in zip(boxes,scores):\n",
    "                cv2.rectangle(im0,\n",
    "                              (box[0], box[1]),\n",
    "                              (box[2]+box[0], box[3]+box[1]),\n",
    "                              (220, 0, 0), 2)\n",
    "                cv2.putText(im0, '%.2f'%(score), (box[0]+np.random.randint(20), box[1]), cv2.FONT_HERSHEY_SIMPLEX ,  \n",
    "                   0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "            ax[count%5][count//5].imshow(im0)\n",
    "            count+=1\n",
    "            \n",
    "        result = {\n",
    "            'image_id': image_id,\n",
    "            'PredictionString': format_prediction_string(boxes, scores)\n",
    "        }\n",
    "\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:06:29.951485Z",
     "iopub.status.busy": "2020-08-11T04:06:29.950689Z",
     "iopub.status.idle": "2020-08-11T04:06:29.992227Z",
     "shell.execute_reply": "2020-08-11T04:06:29.991703Z"
    },
    "papermill": {
     "duration": 0.059326,
     "end_time": "2020-08-11T04:06:29.992320",
     "exception": false,
     "start_time": "2020-08-11T04:06:29.932994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/yolov5pth/weightsbest_yolov5x_fold3.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9e2b9d332ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PredictionString'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-8a297388e898>\u001b[0m in \u001b[0;36mdetect\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load to FP32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/yolov5pth/weightsbest_yolov5x_fold3.pt'"
     ]
    }
   ],
   "source": [
    "results = detect()\n",
    "test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\n",
    "test_df.to_csv('submission.csv', index=False)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T04:06:30.021176Z",
     "iopub.status.busy": "2020-08-11T04:06:30.020371Z",
     "iopub.status.idle": "2020-08-11T04:06:30.733504Z",
     "shell.execute_reply": "2020-08-11T04:06:30.732543Z"
    },
    "papermill": {
     "duration": 0.729198,
     "end_time": "2020-08-11T04:06:30.733629",
     "exception": false,
     "start_time": "2020-08-11T04:06:30.004431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_weights.sh\r\n"
     ]
    }
   ],
   "source": [
    "!ls weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.01195,
     "end_time": "2020-08-11T04:06:30.758210",
     "exception": false,
     "start_time": "2020-08-11T04:06:30.746260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 379.936696,
   "end_time": "2020-08-11T04:06:31.931246",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-11T04:00:11.994550",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0e58fbd1e55f42949c7f7ba85a0c65aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b51831988114ebea2ee692e4d6d22c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0e58fbd1e55f42949c7f7ba85a0c65aa",
       "placeholder": "",
       "style": "IPY_MODEL_d20b42bea3d649d8a96abc1e0669c121",
       "value": " 3373/3373 [05:33&lt;00:00, 10.12it/s]"
      }
     },
     "6d0cdad7dbf5430b99ecb1f4feb73149": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c3132021f19e449e8d9e71d6ed13257b",
        "IPY_MODEL_2b51831988114ebea2ee692e4d6d22c0"
       ],
       "layout": "IPY_MODEL_c81ac8e097cd4499b2611797abd839e1"
      }
     },
     "c3132021f19e449e8d9e71d6ed13257b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ec6e766fc5944b7e9bf9648a96c1e610",
       "max": 3373.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ccd90bac89dd4fb9802c25ea95cf0459",
       "value": 3373.0
      }
     },
     "c81ac8e097cd4499b2611797abd839e1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ccd90bac89dd4fb9802c25ea95cf0459": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "d20b42bea3d649d8a96abc1e0669c121": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ec6e766fc5944b7e9bf9648a96c1e610": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
